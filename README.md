# ğŸ“Œ PrÃ©sentation du Projet

Ce petit projet explore et manipule des modÃ¨les dâ€™apprentissage automatique sur deux jeux de donnÃ©es : **MNIST** et **Binary AlphaDigits**.  
L'objectif principal est d'Ã©valuer et de comparer les performances de trois architectures de rÃ©seaux de neurones spÃ©cifiques :

### ğŸ”¹ Machines de Boltzmann Restreintes (RBM)
- ModÃ¨les probabilistes non supervisÃ©s pour apprendre des reprÃ©sentations latentes.
- ComposÃ©es d'une couche visible et d'une couche cachÃ©e, sans connexions internes.
- Utilisation de l'algorithme **Contrastive Divergence** pour l'apprentissage.

### ğŸ”¹ Deep Belief Networks (DBN)
- Empilement hiÃ©rarchique de plusieurs RBM pour une prÃ©-initialisation efficace des poids.
- Permet lâ€™extraction de caractÃ©ristiques hiÃ©rarchiques des donnÃ©es.

### ğŸ”¹ Deep Neural Networks (DNN)
- RÃ©seaux de neurones profonds entiÃ¨rement connectÃ©s avec **rÃ©tropropagation**.
- EntraÃ®nement **bout Ã  bout** pour une optimisation directe sur tout le rÃ©seau.

##  MÃ©thodologie

Le projet vise Ã  comparer les performances d'un modÃ¨le prÃ©-entraÃ®nÃ© puis fine-tunÃ© pour la classification Ã  celles d'un modÃ¨le entraÃ®nÃ© uniquement pour la tÃ¢che de classification, sans prÃ©-entraÃ®nement.


##  Installation et Utilisation

Pour lancer le code on a juste besoin de de-commenter le code mis entre guillemets dans le fichier principal_DNN_MNIST et lancer lâ€™entrainement du type de modÃ¨le que lâ€™on souhaite. 
